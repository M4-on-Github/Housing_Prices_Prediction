{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6d5ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T02:43:58.123943Z",
     "iopub.status.busy": "2025-12-28T02:43:58.123520Z",
     "iopub.status.idle": "2025-12-28T02:44:01.813701Z",
     "shell.execute_reply": "2025-12-28T02:44:01.812581Z"
    },
    "papermill": {
     "duration": 3.695789,
     "end_time": "2025-12-28T02:44:01.815500",
     "exception": false,
     "start_time": "2025-12-28T02:43:58.119711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n"
     ]
    }
   ],
   "source": [
    "# Set up code checking\n",
    "import os\n",
    "if not os.path.exists(\"../input/train.csv\"):\n",
    "    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n",
    "    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.ml_intermediate.ex4 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bec2e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T02:44:01.821122Z",
     "iopub.status.busy": "2025-12-28T02:44:01.820416Z",
     "iopub.status.idle": "2025-12-28T02:46:34.784537Z",
     "shell.execute_reply": "2025-12-28T02:46:34.783171Z"
    },
    "papermill": {
     "duration": 152.969655,
     "end_time": "2025-12-28T02:46:34.787230",
     "exception": false,
     "start_time": "2025-12-28T02:44:01.817575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Training Stacking Ensemble...\n",
      "Generating predictions...\n",
      "Submission saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. LOAD DATA\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('../input/train.csv', index_col='Id')\n",
    "test = pd.read_csv('../input/test.csv', index_col='Id')\n",
    "\n",
    "# 2. REMOVE OUTLIERS (Crucial for Top 1%)\n",
    "train = train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice'] < 300000)].index)\n",
    "\n",
    "# 3. PREPARE TARGET\n",
    "y = np.log1p(train['SalePrice'])\n",
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test.copy()\n",
    "\n",
    "# Combine for uniform processing\n",
    "all_data = pd.concat([train_features, test_features]).reset_index(drop=True)\n",
    "\n",
    "# 4. CLEANING & FEATURE ENGINEERING\n",
    "# A. Impute LotFrontage by Neighborhood\n",
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# B. Fix specific integer columns that are actually categorical or have special NA meaning\n",
    "# MSSubClass is really a category\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "# GarageYrBlt: missing means no garage, fill with 0 or a placeholder like 1900\n",
    "all_data['GarageYrBlt'] = all_data['GarageYrBlt'].fillna(0)\n",
    "\n",
    "# C. Fill all other missing values (This fixes the ValueError)\n",
    "# Categorical -> \"None\", Numerical -> 0\n",
    "objects = []\n",
    "numerics = []\n",
    "for c in all_data.columns:\n",
    "    if all_data[c].dtype == 'object':\n",
    "        objects.append(c)\n",
    "    else:\n",
    "        numerics.append(c)\n",
    "\n",
    "all_data[objects] = all_data[objects].fillna(\"None\")\n",
    "all_data[numerics] = all_data[numerics].fillna(0)\n",
    "\n",
    "# D. Feature Engineering\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "all_data['TotalBath'] = (all_data['FullBath'] + (0.5 * all_data['HalfBath']) + \n",
    "                         all_data['BsmtFullBath'] + (0.5 * all_data['BsmtHalfBath']))\n",
    "all_data['HasPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['Has2ndFloor'] = all_data['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# E. Skew Correction\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skewness = skewed_feats[abs(skewed_feats) > 0.75]\n",
    "skewed_features = skewness.index\n",
    "all_data[skewed_features] = np.log1p(all_data[skewed_features])\n",
    "\n",
    "# F. Manual Ordinal Encoding\n",
    "ordinal_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0}\n",
    "ordinal_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', \n",
    "                'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']\n",
    "\n",
    "for col in ordinal_cols:\n",
    "    all_data[col] = all_data[col].map(ordinal_map).fillna(0)\n",
    "\n",
    "# G. One-Hot Encoding\n",
    "all_data = pd.get_dummies(all_data)\n",
    "\n",
    "# 5. PREPARE FOR MODELING\n",
    "X = all_data.iloc[:len(y), :]\n",
    "X_test = all_data.iloc[len(y):, :]\n",
    "\n",
    "# Scale data (Important for Ridge/Lasso/SVM)\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 6. DEFINE MODELS\n",
    "# XGBoost (Tree-based)\n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                       max_depth=3, min_child_weight=0,\n",
    "                       gamma=0, subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:squarederror', nthread=-1,\n",
    "                       scale_pos_weight=1, seed=27,\n",
    "                       reg_alpha=0.00006)\n",
    "\n",
    "# Gradient Boosting (Tree-based)\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                max_depth=4, max_features='sqrt',\n",
    "                                min_samples_leaf=15, min_samples_split=10, \n",
    "                                loss='huber', random_state=5)\n",
    "\n",
    "# Ridge/Lasso (Linear)\n",
    "ridge = RidgeCV(alphas=[14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5])\n",
    "lasso = LassoCV(alphas=[0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1], \n",
    "                max_iter=50000, cv=10)\n",
    "\n",
    "# 7. STACKING REGRESSOR\n",
    "# We wrap linear models in a pipeline just to be safe, though we scaled X globally.\n",
    "stack_gen = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('xgb', xgboost), \n",
    "        ('gbr', gbr), \n",
    "        ('ridge', ridge), \n",
    "        ('lasso', lasso)\n",
    "    ],\n",
    "    final_estimator=RidgeCV(),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 8. TRAIN\n",
    "print(\"Training Stacking Ensemble...\")\n",
    "# We use X_scaled for best performance\n",
    "stack_gen.fit(X_scaled, y)\n",
    "\n",
    "# 9. PREDICT\n",
    "print(\"Generating predictions...\")\n",
    "preds_log = stack_gen.predict(X_test_scaled)\n",
    "preds = np.expm1(preds_log)\n",
    "\n",
    "# 10. SAVE\n",
    "output = pd.DataFrame({'Id': test.index, 'SalePrice': preds})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 111096,
     "sourceId": 10211,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 164.660816,
   "end_time": "2025-12-28T02:46:37.409293",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T02:43:52.748477",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
